name: Tests

on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main, dev ]
  workflow_dispatch:  # Allow manual trigger

jobs:
  test:
    name: Test on ${{ matrix.os }} with Python ${{ matrix.python-version }}
    runs-on: ${{ matrix.os }}

    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
        python-version: ['3.10']

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
        cache-dependency-path: |
          requirements.txt
          tests/requirements.txt

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools<82 wheel
        pip install --no-build-isolation -r requirements.txt
        pip install -r tests/requirements.txt

    - name: Run fast tests with coverage
      run: |
        pytest tests/ -v -m "not slow and not requires_audio" --cov=utils --cov=expressions --cov=expressive --cov-report=xml --cov-report=term-missing

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.10'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
        token: ${{ secrets.CODECOV_TOKEN }}

    - name: Upload coverage reports as artifact
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: coverage-${{ matrix.os }}-py${{ matrix.python-version }}
        path: |
          coverage.xml
          htmlcov/
        retention-days: 30

  test-all:
    name: Full test suite on ${{ matrix.os }} (including slow tests)
    runs-on: ${{ matrix.os }}
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        cache: 'pip'
        cache-dependency-path: |
          requirements.txt
          tests/requirements.txt

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools<82 wheel
        pip install --no-build-isolation -r requirements.txt
        pip install -r tests/requirements.txt

    - name: Run all tests (including slow tests)
      run: |
        pytest tests/ -v --cov=utils --cov=expressions --cov=expressive --cov-report=xml --cov-report=term-missing

    - name: Upload full coverage report
      uses: actions/upload-artifact@v4
      with:
        name: coverage-full-${{ matrix.os }}
        path: |
          coverage.xml
          htmlcov/
        retention-days: 30

  lint:
    name: Code quality checks
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r tests/requirements.txt

    - name: Run flake8
      run: |
        flake8 utils/ expressions/ expressive.py --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 utils/ expressions/ expressive.py --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      continue-on-error: true

    - name: Check code formatting with black
      run: |
        black --check utils/ expressions/ expressive.py tests/
      continue-on-error: true

    - name: Check import sorting with isort
      run: |
        isort --check-only utils/ expressions/ expressive.py tests/
      continue-on-error: true

  summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test, lint]
    if: always()

    steps:
    - name: Check test results
      run: |
        if [ "${{ needs.test.result }}" == "success" ]; then
          echo "✅ All tests passed!"
        else
          echo "❌ Some tests failed!"
          exit 1
        fi
